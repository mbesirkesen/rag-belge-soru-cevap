import os
import sys
import traceback
import gradio as gr
from dotenv import load_dotenv

# .env yÃ¼kle
load_dotenv()

# core modÃ¼lÃ¼nden importlar
from core import (
    DATA_DIR,
    PERSIST_DIR,
    ensure_dirs,
    build_or_update_vectorstore,
    load_documents,
    split_documents,
    get_retriever,
    get_llm,
    safe_compose_context,
    context_is_relevant,
    reduce_repetition,
    build_prompt,
)

def ui_answer(message, history_state, k_value, use_mmr, prompt_format, use_turkish_embedding):
    """
    Sohbet Fonksiyonu
    Input: Mesaj ve Gizli GeÃ§miÅŸ (history_state)
    Output: (BoÅŸ mesaj kutusu, Chatbot gÃ¶rÃ¼nÃ¼mÃ¼, GÃ¼ncel Gizli GeÃ§miÅŸ)
    """
    if history_state is None:
        history_state = []

    try:
        # RAG Ä°ÅŸlemleri
        retriever = get_retriever(
            PERSIST_DIR, 
            k=int(k_value), 
            use_mmr=use_mmr,
            turkish_focused=use_turkish_embedding
        )
        docs = retriever.invoke(message)
        context = safe_compose_context(docs)
        llm = get_llm()
        prompt = build_prompt(message, context, prompt_format)
        
        if not context or not context_is_relevant(message, context):
            answer = "Bu belgeden Ã§Ä±karamÄ±yorum."
            sources = []
        else:
            answer = llm.invoke(prompt).strip()
            answer = reduce_repetition(answer)
            source_list = [d.metadata.get("source", "?") for d in docs]
            source_list = list(dict.fromkeys(source_list))
            sources = source_list

        # KaynaklarÄ± ekle
        if sources:
            source_text = "\n".join(f"- {src}" for src in sources)
            full_response = answer + f"\n\nKaynaklar:\n{source_text}"
        else:
            full_response = answer

        # GeÃ§miÅŸe ekle (User, Bot)
        history_state.append((message, full_response))
        
        # 1. Msg kutusunu temizle ("")
        # 2. Chatbot'a geÃ§miÅŸi ver (history_state)
        # 3. State'i gÃ¼ncelle (history_state)
        return "", history_state, history_state

    except Exception as e:
        print(f"Hata: {e}")
        traceback.print_exc()
        error_msg = f"Hata oluÅŸtu: {str(e)}"
        history_state.append((message, error_msg))
        return "", history_state, history_state


def ui_upload(files):
    """
    Dosya yÃ¼kleme fonksiyonu
    """
    print("--- Dosya YÃ¼kleme Ä°steÄŸi Geldi ---")
    
    # 422 HatasÄ± iÃ§in gÃ¼venlik kontrolÃ¼
    if files is None:
        return "âš ï¸ Dosya seÃ§ilmedi."
        
    # Gradio versiyonuna gÃ¶re files listesi veya tek obje gelebilir
    file_paths = []
    
    # Liste mi deÄŸil mi kontrol et
    if isinstance(files, list):
        for f in files:
            # Gradio dosyayÄ± bir nesne olarak mÄ± yoksa string yol olarak mÄ± gÃ¶nderiyor?
            if isinstance(f, str):
                file_paths.append(f)
            elif hasattr(f, 'name'): # Gradio temp file objesi
                file_paths.append(f.name)
    elif isinstance(files, str):
        file_paths.append(files)
    elif hasattr(files, 'name'):
        file_paths.append(files.name)

    if not file_paths:
        return "âš ï¸ Dosya yolu okunamadÄ±."

    print(f"Ä°ÅŸlenecek dosyalar: {file_paths}")
    
    saved_paths = []
    ensure_dirs()

    try:
        # DosyalarÄ± kopyala
        import shutil
        for src_path in file_paths:
            filename = os.path.basename(src_path)
            target_path = os.path.join(DATA_DIR, filename)
            shutil.copy2(src_path, target_path)
            saved_paths.append(target_path)

        # Ä°ndeksle
        docs = load_documents(saved_paths)
        if not docs:
            return "âŒ Metin okunamadÄ±."
            
        chunks = split_documents(docs)
        build_or_update_vectorstore(chunks, persist_directory=PERSIST_DIR)
        
        return f"âœ… BaÅŸarÄ±lÄ±! {len(chunks)} parÃ§a eklendi."

    except Exception as e:
        print(f"Upload HatasÄ±: {e}")
        traceback.print_exc()
        return f"âŒ Hata: {str(e)}"


def build_demo():
    ensure_dirs()
    
    # CSS: Chatbot yÃ¼ksekliÄŸi
    css = "#chatbot {height: 500px !important; overflow: auto;}"

    with gr.Blocks(title="RAG AsistanÄ±", css=css) as demo:
        # --- STATE (Gizli HafÄ±za) ---
        # Chatbot'u input olarak kullanmak yerine bunu kullanacaÄŸÄ±z
        history_state = gr.State([]) 

        gr.Markdown("## ğŸ“„ Belge Soru-Cevap Sistemi")

        with gr.Row():
            with gr.Column(scale=1):
                file_uploader = gr.File(
                    label="PDF/TXT YÃ¼kle", 
                    file_types=[".pdf", ".txt"], 
                    file_count="multiple",
                    type="filepath" # Bu ayar Ã¶nemli
                )
                upload_btn = gr.Button("Ä°ndeksi GÃ¼ncelle", variant="primary")
                upload_info = gr.Textbox(label="Durum", interactive=False)
            
            with gr.Column(scale=2):
                chatbot = gr.Chatbot(label="Sohbet", elem_id="chatbot")
                with gr.Row():
                    msg = gr.Textbox(
                        label="Sorunuz", 
                        placeholder="YazÄ±n ve Enter'a basÄ±n...",
                        scale=4
                    )
                    clear = gr.Button("Temizle", scale=1)

        with gr.Accordion("Ayarlar", open=False):
            k_slider = gr.Slider(minimum=1, maximum=10, value=4, step=1, label="k")
            mmr_checkbox = gr.Checkbox(value=True, label="MMR")
            prompt_format = gr.Dropdown(["kÄ±sa", "madde", "Ã¶zet_madde"], value="kÄ±sa", label="Format")
            turkish_embedding = gr.Checkbox(value=False, label="TR Embedding")

        # --- OLAYLAR (EVENTS) ---
        
        # 1. Upload Butonu
        upload_btn.click(
            fn=ui_upload, 
            inputs=[file_uploader], 
            outputs=[upload_info]
        )

        # 2. Mesaj GÃ¶nderme
        # DÄ°KKAT: inputs iÃ§inde 'chatbot' YOK. 'history_state' VAR.
        msg.submit(
            fn=ui_answer,
            inputs=[msg, history_state, k_slider, mmr_checkbox, prompt_format, turkish_embedding],
            outputs=[msg, chatbot, history_state] # Ã‡Ä±ktÄ± sÄ±rasÄ±: MesajKutusu, GÃ¶rselChat, GizliState
        )

        # 3. Temizle
        def clear_history():
            return [], [] # Hem chatbot hem state temizlenir
            
        clear.click(fn=clear_history, inputs=None, outputs=[chatbot, history_state])

    return demo

if __name__ == "__main__":
    base_port = int(os.getenv("SERVER_PORT", "7860"))
    
    demo = build_demo()
    
    # Port Ã§akÄ±ÅŸmasÄ± durumunda alternatif portlarÄ± dene
    for port_offset in range(10):
        try:
            port = base_port + port_offset
            print(f"BaÅŸlatÄ±lÄ±yor... Port: {port}")
            demo.launch(server_port=port, share=False)
            break
        except OSError as e:
            if "Cannot find empty port" in str(e) or "Port" in str(e):
                print(f"Port {port} kullanÄ±mda, {port + 1} deniyor...")
                continue
            else:
                raise
    else:
        print(f"âŒ 7860-7869 arasÄ± tÃ¼m portlar kullanÄ±mda!")
        print("LÃ¼tfen bir Python iÅŸlemini durdurun veya SERVER_PORT deÄŸiÅŸkenini ayarlayÄ±n.")